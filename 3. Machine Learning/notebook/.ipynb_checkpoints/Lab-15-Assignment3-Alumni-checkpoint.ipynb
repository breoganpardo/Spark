{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 16 Assignment 3 - Group Assignment\n",
    "\n",
    "When creating ML models, the concept of efficiency has three sides:\n",
    "1. The time dedicated by the analyst to build the model\n",
    "2. The computer time and resources needed by the final model\n",
    "3. The accuracy of the final model\n",
    "\n",
    "Efficiency is a combination of all\n",
    "\n",
    "In this assignment, you are asked to be efficient. Spark is the best tool to build models over massive datasets\n",
    "\n",
    "If you need to create Spark+Python Machine Learning models that \"run fast\" on the  cluster, you must avoid using Python code or working with RRD+python. Try to use  the already existing methods that do what you need (do not reinvent the wheel).\n",
    "\n",
    "Therefore try to use the implemented object+methods inside the Spark SQL and ML modules. They are very fast, because it is compiled Java/Scala code. Try to use: DataFrames, Feature Transfomers, Estimators, Pipelines, GridSearch, CV, ...\n",
    "\n",
    "For this assignment, you are asked to create a classification model that:\n",
    "1. Uses the variables in the dataset (train.csv) to predict label \"loan_status\"\n",
    "2. Write a python scripts that:\n",
    "    - Reads the \"train.csv\" and \"test.csv\" files, transform and select variables as you wish.\n",
    "    - Train/fit your model using the \"train.csv\".\n",
    "    - Predict your model on the \"test.csv\" ( you should generate a file with your predictions).\n",
    "    - I will use a different test dataset (with the true loan_status).\n",
    "\n",
    "Your work will be evaluated under the following scoring schema\n",
    "- (40%) ETL process\n",
    "- (40%) Model train process\n",
    "- (10%) Code Readability \n",
    "- (10%) AUC on the test set (at least 50%)\n",
    "\n",
    "Enjoy it and best of luck!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Assignment is based on kaggle competition https://www.kaggle.com/c/loan-default-prediction from where a sub-dataset has been taken.\n",
    "\n",
    "### File descriptions\n",
    "**train.csv** - the training set (to use for building a model)\n",
    "\n",
    "**test.csv** - the test set (to use for applying predictings)\n",
    "\n",
    "**sample_submission.csv** - a template for the submission file\n",
    "\n",
    "### Data Description (also contained in LendingClub_DataDescription.csv)\n",
    "**ID**: A unique LC assigned ID for the loan listing.\n",
    "\n",
    "**loan_amnt**: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n",
    "\n",
    "**loan_status**: Current status of the loan (**Target**: 1 = Charged Off, 0 = Fully Paid).\n",
    "\n",
    "**term**: The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "\n",
    "**int_rate**: Interest Rate on the loan.\n",
    "\n",
    "**installment**: The monthly payment owed by the borrower if the loan originates.\n",
    "\n",
    "**emp_length**: Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "\n",
    "**home_ownership**: The home ownership status provided by the borrower during registration. Our values are: OTHER/NONE, MORTGAGE, OWN, RENT.\n",
    "\n",
    "**annual_inc**: The self-reported annual income provided by the borrower during registration.\n",
    "\n",
    "**purpose**: A category provided by the borrower for the loan request.\n",
    "\n",
    "**title**: The loan title provided by the borrower.\n",
    "\n",
    "**STATE**: The state provided by the borrower in the loan application.\n",
    "\n",
    "**delinq_2yrs**: The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years.\n",
    "\n",
    "**revol_bal**: Total credit revolving balance.\n",
    "\n",
    "**revol_util**: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
    "\n",
    "**total_pymnt**: Indicates total payment at the end of the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"C:\\\\spark-2.3.2-bin-hadoop2.7\\\\\"\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. Please check your installation\n",
    "#to make sure that these zip files actually exist. The names might change\n",
    "#as versions change.\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "#Initialize SparkSession and SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a Spark Session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"MiPrimer\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.cores.max\",\"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "#Get the Spark Context from Spark Session    \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the files into a Dataframes and show them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = \n",
    "\n",
    "testDF = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analizing null values, cross tables distribution and covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETL summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should explain how you are going to clean and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Spark code about the one explained in \"ETL Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Spark code about the transformations you apply to the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Code to assemble the variables to a numerical vector (VectorAssembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create Pipeline for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regresion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Write a function \"metrics\" which has a LogisticRegressionModel.summary as input attribute and produces an output of: \n",
    "1. Area under ROC\n",
    "2. False Positive Rate By Label\n",
    "3. True Positive Rate By Label\n",
    "4. Precision By Label\n",
    "5. Recall By Label\n",
    "6. fMeasure By Label\n",
    "7. Accuracy\n",
    "8. False Positive Rate\n",
    "9. True Positive Rate\n",
    "10. fMeasure\n",
    "11. Precision\n",
    "12. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(trainingSummary):\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Apply a Logistic Regresion Base Model and show the metrics by the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 We are going to try to improve our model:\n",
    "1. Using a `weight column` in our Logistic Regression Model (Take into account we are working with a unbalanced dataset)\n",
    "2. Define a `ParamGridBuilder` with `regParam`, `elasticNetParam` and `maxIter` at least\n",
    "3. Define an `BinaryClassificationEvaluator`\n",
    "4. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which are the metrics of the best model (training) in the 5 k-fold runs? (Use the function above)\n",
    "5. Which is the ROC-AUC on validation dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest Model\n",
    "1. Define a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Model\n",
    "1. Defining a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least (You can use the above one)\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Apply your best model to send the predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
